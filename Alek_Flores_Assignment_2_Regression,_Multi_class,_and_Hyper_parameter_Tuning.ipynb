{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "705ccee2",
      "metadata": {
        "id": "705ccee2"
      },
      "source": [
        "# Assignment 2: Regression, Multi-class, and Hyper-parameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e81dbbc",
      "metadata": {
        "id": "8e81dbbc"
      },
      "source": [
        "### Task 1: Regression Metrics (30 points total)\n",
        "\n",
        "The code below executes the following steps:\n",
        "* Load the California Housing dataset from sklearn.\n",
        "* Split the dataset into training and testing sets.\n",
        "* Train a linear regression model on the training data.\n",
        "\n",
        "It is your task to:\n",
        "* Evaluate the model's performance using Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared metrics.\n",
        "* Print the evaluation results.\n",
        "* Interpret the results and discuss how each metric reflects the performance of a regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a631ea7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a631ea7",
        "outputId": "553265b2-9e26-4386-9144-70fbaa4a040b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.5332\n",
            "Mean Squared Error (MSE): 0.5559\n",
            "R-squared (R²): 0.5758\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared (R²): {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca0fcbb",
      "metadata": {
        "id": "5ca0fcbb"
      },
      "source": [
        "**Question: Interpret the results. How might we interpret the model performance and communicate it to stakeholders? (20 points)**\n",
        "\n",
        "MAE is the average difference between predicted values and actual values. Since we have an MAE of .53, in housing prices it means, on average, the predcited price was off by $53,000 from the actual price. MSE is the average of the squared difference between predicted vs actual price. Since the differences are squared, it penalizes large errors. R-squared is different. It explains how well the model performs using the variables. The closer the R-squared is to 1 the better the model performed. In this dataset, using the variables we selected, the model can knows about 61% how what drives the housing prices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e577b164",
      "metadata": {
        "id": "e577b164"
      },
      "source": [
        "*Your Answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ebf001c",
      "metadata": {
        "id": "5ebf001c"
      },
      "source": [
        "### Task 2: Multiclass Classification Metrics (30 points total)\n",
        "\n",
        "The code below executes the following steps:\n",
        "* Load the Iris dataset from scikit-learn.\n",
        "* Split the dataset into training and testing sets.\n",
        "* Train a multiclass classification model, logistic regression, on the training data.\n",
        "\n",
        "It is your task to:\n",
        "* Evaluate the model's performance using precision, recall, F1 score\n",
        "* Visualize a confusion matrix.\n",
        "* Print the evaluation results.\n",
        "* Interpret the results and discuss how each metric reflects the performance of a regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd7ba5a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd7ba5a2",
        "outputId": "7a526934-2905-453d-969d-9aa104dc1dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f37be54",
      "metadata": {
        "id": "7f37be54"
      },
      "source": [
        "**Question: Interpret the results. How might we interpret the model performance and communicate it to stakeholders? (20 points)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34b801e0",
      "metadata": {
        "id": "34b801e0"
      },
      "source": [
        "*Your Answer:*\n",
        "According to the numbers above, the model performs very well. It makes little to no, incorrect predictions, little to no miss classified species, and g"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acd0e7e8",
      "metadata": {
        "id": "acd0e7e8"
      },
      "source": [
        "### Task 3: Model Selection, Hyperparameter Tuning, and Cross-Validation (40 points total)\n",
        "The code below executes the following steps:\n",
        "* Load in the Iris dataset.\n",
        "* Split into training and testing\n",
        "\n",
        "It is your task to:\n",
        "* Implement a grid search with cross-validation to tune hyperparameters for a classification model (e.g. random forest).\n",
        "* Explore different hyperparameters (e.g. number of estimators for random forest).\n",
        "* Evaluate the model's performance using accuracy, precision, recall, and F1 score on the testing set.\n",
        "* Print the **best hyperparameters** and evaluation results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce9cd1f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce9cd1f7",
        "outputId": "c746a660-db21-4592-e28d-ac7cb45a647f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "Cross-validation scores: [0.96666667 0.96666667 0.93333333 0.9        1.        ]\n",
            "Mean cross-validation accuracy: 0.9533333333333334\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for the RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20],     # Maximum depth of each tree\n",
        "    'min_samples_split': [2, 5, 10], # Minimum samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]     # Minimum samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Create a RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform GridSearchCV with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Get the best model and its hyperparameters\n",
        "best_rf = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#Optional:  Evaluate using cross-validation on the entire dataset to get a more robust estimate.\n",
        "cv_scores = cross_val_score(best_rf, X, y, cv=5, scoring='accuracy')\n",
        "print(\"\\nCross-validation scores:\", cv_scores)\n",
        "print(\"Mean cross-validation accuracy:\", cv_scores.mean())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd1f4fa",
      "metadata": {
        "id": "9bd1f4fa"
      },
      "source": [
        "### OPTIONAL Task 4: Custom Scoring Metric (20 bonus points)\n",
        "\n",
        "In sklearn, you are not limited to using their scoring functions. You can create your own!\n",
        "\n",
        "You can create a custom scoring metric in scikit-learn by defining a scoring function and then using the `make_scorer` function to wrap it as a scorer.\n",
        "\n",
        "**For bonus points:**\n",
        "\n",
        "* Define a custom scoring function custom_scoring that calculates the weighted sum of precision and recall for a binary classification problem.\n",
        "* Then wrap this function using make_scorer to create a custom scorer custom_scorer.\n",
        "* Use this custom scorer in cross-validation to evaluate the performance of a logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb03387",
      "metadata": {
        "id": "cbb03387"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define your custom scoring function\n",
        "def custom_scoring(y_true, y_pred, precision_weight = 0.6, recall_weight = 0.4):\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    return score\n",
        "\n",
        "# Wrap the custom scoring function as a scorer\n",
        "# YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bbb6ae",
      "metadata": {
        "id": "46bbb6ae"
      },
      "outputs": [],
      "source": [
        "# THIS CODE TESTS YOUR FUNCTION\n",
        "# Generate sample data\n",
        "X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n",
        "\n",
        "# Create and train a model using cross-validation\n",
        "model = LogisticRegression()\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring=custom_scorer)\n",
        "\n",
        "# Print the custom scores obtained from cross-validation\n",
        "print(\"Custom Scores:\", scores)\n",
        "print(\"Mean Custom Score:\", scores.mean())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}