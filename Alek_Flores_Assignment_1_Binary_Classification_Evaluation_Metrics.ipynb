{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d37a6bc0",
      "metadata": {
        "id": "d37a6bc0"
      },
      "source": [
        "# Assignment 1 - Binary Classification Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aud5GsKaVnGZ"
      },
      "id": "aud5GsKaVnGZ"
    },
    {
      "cell_type": "markdown",
      "id": "d1679a82",
      "metadata": {
        "id": "d1679a82"
      },
      "source": [
        "**Objective:**\n",
        "The objective of this assignment is to assess your understanding of fundamental concepts in model evaluation for machine learning tasks. This assignment covers topics discussed in the first half of the course, including key evaluation metrics, confusion matrices, ROC curves, and Precision-Recall curves.\n",
        "Instructions:\n",
        "\n",
        "1. Theory Questions:\n",
        "Answer the following theoretical questions:\n",
        "\n",
        "    1. Explain the limitations of accuracy as an evaluation metric in imbalanced datasets. How does accuracy behave when classes are heavily skewed, and why might it provide misleading results?\n",
        "    2. Describe the purpose and interpretation of a confusion matrix. How does it help in assessing a classification model's performance?\n",
        "    3. Explain the concept of ROC curves. What does each point on an ROC curve represent? How is the area under the ROC curve (AUC-ROC) calculated?\n",
        "    4. Compare and contrast the advantages and disadvantages of ROC curves and Precision-Recall curves. In what scenarios would you prefer to use one over the other, and why?\n",
        "\n",
        "2. Practical Exercises:\n",
        "* Implement Python code to calculate the following evaluation metrics for a given binary classification problem: Log Loss\n",
        "* Select the best metric for an applied scenario\n",
        "\n",
        "**Submission Guidelines:**\n",
        "* Submit your responses to the theory questions in a neatly organized markdown.\n",
        "* Include your Python code for the practical exercise.\n",
        "* Submit your assignment as a single `.ipynb` file named `MY NAME Assignment 1 - Log Loss` via the course submission platform (slack)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58864fe",
      "metadata": {
        "id": "e58864fe"
      },
      "source": [
        "## Part 1: Theory Questions (20 points)\n",
        "Provide your answers here:\n",
        "\n",
        "    1. Accuracy tends to be biased towards the majority class. Since the formula for accuracy is true positives plus true negatives overall all samples, it can give a higher accuracy that mask the performance of the model predicting the minority class.\n",
        "    2. The primary purpose of a confusion matrix is to provide a comprehensive summary of a classification model's performance across all classes. It summarizes the counts for true positives, true negatives, false positives, and false negatives predictions made by a classification model.\n",
        "    3. A Receiver Operating Characteristic (ROC) curve is a graphical representation of the performance of a binary classification model at various classification thresholds. Each point on the ROC curve corresponds to a specific classification threshold.  The threshold determines the boundary separating positive and negative predictions.\n",
        "    4. Both ROC curves and Precision-Recall (PR) curves are valuable tools for evaluating the performance of classification models, particularly in scenarios with imbalanced datasets. Advantages of ROC is that it focuses on enitre range of thresholds, insensitive to class imbalance, and it uses single summary statistics. Advantages to precision-recall curve is that it focuses on positive class performance, it's sensitive to class imbalance, and better for imbalanced datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8c2adb",
      "metadata": {
        "id": "8b8c2adb"
      },
      "source": [
        "## Practicing Log Loss (25 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f4dca41",
      "metadata": {
        "id": "2f4dca41"
      },
      "source": [
        "**Objective:**\n",
        "The objective of this assignment is to deepen your understanding of log loss, also known as logarithmic loss or cross-entropy loss, and its application in evaluating the performance of classification models.\n",
        "\n",
        "**Instructions:**\n",
        "In this assignment, you will be given a set of binary classification predictions along with their corresponding actual class labels. Your task is to calculate the log loss for each prediction and then analyze the overall log loss performance of the model.\n",
        "\n",
        "**Dataset:**\n",
        "You are provided with a dataset containing the following information:\n",
        "\n",
        "Predicted probabilities for the positive class (ranging from 0 to 1) for a set of instances.\n",
        "Actual binary class labels (0 or 1) indicating whether the instance belongs to the positive class or not.\n",
        "\n",
        "**Assignment Tasks:**\n",
        "1. Calculate the log loss for each instance in the dataset using the predicted probabilities and actual class labels.\n",
        "2. Summarize the individual log losses and compute the overall log loss performance for the model.\n",
        "3. Interpret the overall log loss value and analyze the model's performance. Discuss any insights or observations derived from the log loss analysis.\n",
        "\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "| Instance | Predicted Probability | Actual Label |\n",
        "|----------|------------------------|--------------|\n",
        "|    1     |          0.9           |       1      |\n",
        "|    2     |          0.3           |       0      |\n",
        "|    3     |          0.6           |       1      |\n",
        "|    4     |          0.8           |       0      |\n",
        "|    5     |          0.1           |       1      |\n",
        "\n",
        "\n",
        "**Grading Criteria:**\n",
        "\n",
        "* Correctness of log loss calculations.\n",
        "* Clarity and completeness of the analysis.\n",
        "* Insights derived from the log loss interpretation.\n",
        "* Overall presentation and adherence to submission guidelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dad6832",
      "metadata": {
        "id": "3dad6832",
        "outputId": "1956ec64-66c9-46ec-ff1c-765784ec0b1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Instance  Predicted Probability  Actual Label\n",
            "0         1                    0.9             1\n",
            "1         2                    0.3             0\n",
            "2         3                    0.6             1\n",
            "3         4                    0.8             0\n",
            "4         5                    0.1             1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a DataFrame with the dataset\n",
        "data = {\n",
        "    'Instance': [1, 2, 3, 4, 5],\n",
        "    'Predicted Probability': [0.9, 0.3, 0.6, 0.8, 0.1],\n",
        "    'Actual Label': [1, 0, 1, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be2a3c3",
      "metadata": {
        "id": "9be2a3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d078e9-e6c0-4d7e-d6a3-ffcd7be45302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Instance  Predicted Probability  Actual Label  Log Loss\n",
            "0         1                    0.9             1  0.105361\n",
            "1         2                    0.3             0  0.356675\n",
            "2         3                    0.6             1  0.510826\n",
            "3         4                    0.8             0  1.609438\n",
            "4         5                    0.1             1  2.302585\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "df['Log Loss'] = - (df['Actual Label'] * np.log(df['Predicted Probability']) +\n",
        "                    (1 - df['Actual Label']) * np.log(1 - df['Predicted Probability']))\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "over_all_log_loss = df['Log Loss'].mean()\n",
        "print(df)\n",
        "print(f\"Overall Log Loss: {over_all_log_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OGoUEf18IH7",
        "outputId": "208ee505-c02d-4613-b6da-526f453554cc"
      },
      "id": "_OGoUEf18IH7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Instance  Predicted Probability  Actual Label  Log Loss\n",
            "0         1                    0.9             1  0.105361\n",
            "1         2                    0.3             0  0.356675\n",
            "2         3                    0.6             1  0.510826\n",
            "3         4                    0.8             0  1.609438\n",
            "4         5                    0.1             1  2.302585\n",
            "Overall Log Loss: 0.976976817758139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Instance': [1, 2, 3, 4, 5],\n",
        "    'Predicted Probability': [0.6, 0.3, 0.6, 0.8, 0.1],\n",
        "    'Actual Label': [1, 0, 1, 0, 1],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df\n",
        "\n",
        "df['Log Loss'] = - (df['Actual Label'] * np.log(df['Predicted Probability']) +\n",
        "                    (1 - df['Actual Label']) * np.log(1 - df['Predicted Probability']))\n",
        "\n",
        "over_all_log_loss = df['Log Loss'].mean()\n",
        "\n",
        "print(df)\n",
        "print(f\"Overall Log Loss: {over_all_log_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGij0nnMED1w",
        "outputId": "3f0da1c6-e845-4f0e-ac4b-103c0f094664"
      },
      "id": "LGij0nnMED1w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Instance  Predicted Probability  Actual Label  Log Loss\n",
            "0         1                    0.6             1  0.510826\n",
            "1         2                    0.3             0  0.356675\n",
            "2         3                    0.6             1  0.510826\n",
            "3         4                    0.8             0  1.609438\n",
            "4         5                    0.1             1  2.302585\n",
            "Overall Log Loss: 1.058069839379772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaa92db1",
      "metadata": {
        "id": "eaa92db1"
      },
      "source": [
        "*Question: Interpret the log loss above. How would it change if the predicted probability for instance 0 changed from 0.9 to 0.6? Why?*\n",
        "\n",
        " The log loss is used to evaluate the performance of a model on how accurately and confindently, it can predict and outcomes classification. For log loss the closer it is to 0 the better it's performing. For our data set above the average log loss is .976, which is not the best performance. Now if we switched, instance 1, predicted probabilty from .9 to .6, we get an overall log loss of 1.05. Even though predictions was correct, it was not as confident when it was .9 hurting the overall performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abec414",
      "metadata": {
        "id": "2abec414"
      },
      "source": [
        "*Your answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972c7485",
      "metadata": {
        "id": "972c7485"
      },
      "source": [
        "*Question: Why might you select log loss over precision, recall, or accuracy (in the context of any problem, not this one specifically)?*\n",
        "\n",
        "log loss not only measures correctness but also confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b26ee2",
      "metadata": {
        "id": "88b26ee2"
      },
      "source": [
        "*Your answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a69ed6d7",
      "metadata": {
        "id": "a69ed6d7"
      },
      "source": [
        "## Application Scenario: Select a Metric (55 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791158c2",
      "metadata": {
        "id": "791158c2"
      },
      "source": [
        "**Application Scenario: Fraud Detection System**\n",
        "\n",
        "You are working as a data scientist for a financial institution that wants to develop a fraud detection system to identify potentially fraudulent transactions. The dataset contains information about various transactions, including transaction amount, merchant ID, and transaction type. Your task is to build a machine learning model to classify transactions as either fraudulent or non-fraudulent.\n",
        "\n",
        "**Problem Description:**\n",
        "\n",
        "* Dataset: The dataset consists of historical transaction data, with labels indicating whether each transaction was fraudulent or not.\n",
        "* Class Distribution: The dataset is mostly non-fraudulant cases, with a small percentage of transactions being fraudulent compared to legitimate transactions.\n",
        "* Objective: The objective is to develop a fraud detection model that minimizes false negatives (fraudulent transactions incorrectly classified as non-fraudulent) while maintaining a reasonable level of precision.\n",
        "\n",
        "**Stakeholder Requirements:**\n",
        "Given the nature of the problem, it is crucial to prioritize recall (sensitivity) to ensure that as many fraudulent transactions as possible are detected. However, precision is also important to minimize false positives and avoid unnecessary investigations of legitimate transactions. Minimizing false negatives (missing fraudulent transactions) is of utmost importance.\n",
        "\n",
        "**Task:**\n",
        "Your task is to develop Python code to evaluate the performance of different machine learning models using various evaluation metrics, including accuracy, precision, recall, and F2 score. *Select the evaluation metric that best suits the problem and explain your choice*.\n",
        "\n",
        "**Additional Guidelines:**\n",
        "* You should preprocess the dataset as needed and split it into training and testing sets.\n",
        "* Implement machine learning models of your choice (e.g., logistic regression, random forest) and evaluate their performance.\n",
        "* Use appropriate evaluation metrics for binary classification tasks.\n",
        "* Discuss the rationale behind your choice of evaluation metric and how it aligns with the problem requirements.\n",
        "* Present your findings and recommendations for selecting the best model based on the chosen evaluation metric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4f0e46",
      "metadata": {
        "id": "dc4f0e46"
      },
      "source": [
        "**Dataset Sample:**\n",
        "\n",
        "| Transaction ID | Transaction Amount | Merchant ID | Transaction Type | Fraudulent |\n",
        "|----------------|--------------------|-------------|------------------|------------|\n",
        "| 1              | 1000               | M123        | Online Purchase  | 0          |\n",
        "| 2              | 500                | M456        | ATM Withdrawal   | 0          |\n",
        "| 3              | 2000               | M789        | Online Purchase  | 1          |\n",
        "| 4              | 1500               | M123        | POS Transaction  | 0          |\n",
        "| 5              | 800                | M456        | Online Purchase  | 0          |\n",
        "| 6              | 3000               | M789        | ATM Withdrawal   | 1          |\n",
        "\n",
        "* Transaction ID: Unique identifier for each transaction.\n",
        "* Transaction Amount: The amount of money involved in the transaction.\n",
        "* Merchant ID: Identifier for the merchant involved in the transaction.\n",
        "* Transaction Type: The type of transaction (e.g., online purchase, ATM withdrawal, POS transaction).\n",
        "* Fraudulent: Binary indicator (0 or 1) specifying whether the transaction is fraudulent (1) or not (0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc1ec81",
      "metadata": {
        "id": "1bc1ec81",
        "outputId": "796d6400-7c50-4a66-c389-845b7d6234e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Transaction ID  Transaction Amount Merchant ID Transaction Type  \\\n",
            "0                1                1000        M123  Online Purchase   \n",
            "1                2                 500        M456   ATM Withdrawal   \n",
            "2                3                2000        M789  Online Purchase   \n",
            "3                4                1500        M123  POS Transaction   \n",
            "4                5                 800        M456  Online Purchase   \n",
            "5                6                3000        M789   ATM Withdrawal   \n",
            "6                7                1200        M123  Online Purchase   \n",
            "7                8                 700        M456   ATM Withdrawal   \n",
            "8                9                1800        M789  Online Purchase   \n",
            "9               10                1300        M123  POS Transaction   \n",
            "10              11                 900        M456  Online Purchase   \n",
            "11              12                 400        M789   ATM Withdrawal   \n",
            "12              13                2200        M123  Online Purchase   \n",
            "13              14                1600        M456   ATM Withdrawal   \n",
            "14              15                 850        M789  Online Purchase   \n",
            "15              16                2800        M123  POS Transaction   \n",
            "16              17                1100        M456  Online Purchase   \n",
            "17              18                 600        M789   ATM Withdrawal   \n",
            "18              19                1900        M123  Online Purchase   \n",
            "19              20                1400        M456   ATM Withdrawal   \n",
            "20              21                 950        M123  Online Purchase   \n",
            "21              22                 300        M456   ATM Withdrawal   \n",
            "22              23                2100        M789  Online Purchase   \n",
            "23              24                1700        M123  POS Transaction   \n",
            "24              25                 820        M456  Online Purchase   \n",
            "25              26                3200        M789   ATM Withdrawal   \n",
            "26              27                1250        M123  Online Purchase   \n",
            "27              28                 720        M456   ATM Withdrawal   \n",
            "28              29                1850        M789  Online Purchase   \n",
            "29              30                1350        M123  POS Transaction   \n",
            "30              31                 880        M456  Online Purchase   \n",
            "31              32                 420        M789   ATM Withdrawal   \n",
            "32              33                2400        M123  Online Purchase   \n",
            "33              34                1750        M456   ATM Withdrawal   \n",
            "34              35                 830        M789  Online Purchase   \n",
            "35              36                3100        M123  POS Transaction   \n",
            "36              37                1150        M456  Online Purchase   \n",
            "37              38                 620        M789   ATM Withdrawal   \n",
            "38              39                1950        M123  Online Purchase   \n",
            "39              40                1450        M456   ATM Withdrawal   \n",
            "\n",
            "    Fraudulent  \n",
            "0            0  \n",
            "1            0  \n",
            "2            1  \n",
            "3            0  \n",
            "4            0  \n",
            "5            1  \n",
            "6            0  \n",
            "7            0  \n",
            "8            1  \n",
            "9            0  \n",
            "10           0  \n",
            "11           1  \n",
            "12           0  \n",
            "13           0  \n",
            "14           1  \n",
            "15           0  \n",
            "16           0  \n",
            "17           1  \n",
            "18           0  \n",
            "19           0  \n",
            "20           1  \n",
            "21           0  \n",
            "22           0  \n",
            "23           1  \n",
            "24           0  \n",
            "25           0  \n",
            "26           1  \n",
            "27           0  \n",
            "28           0  \n",
            "29           1  \n",
            "30           0  \n",
            "31           0  \n",
            "32           1  \n",
            "33           0  \n",
            "34           0  \n",
            "35           1  \n",
            "36           0  \n",
            "37           0  \n",
            "38           1  \n",
            "39           0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating the dataset\n",
        "data = {\n",
        "    'Transaction ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
        "                       11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "                       21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
        "                       31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
        "    'Transaction Amount': [1000, 500, 2000, 1500, 800, 3000, 1200, 700, 1800, 1300,\n",
        "                           900, 400, 2200, 1600, 850, 2800, 1100, 600, 1900, 1400,\n",
        "                           950, 300, 2100, 1700, 820, 3200, 1250, 720, 1850, 1350,\n",
        "                           880, 420, 2400, 1750, 830, 3100, 1150, 620, 1950, 1450],\n",
        "    'Merchant ID': ['M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456',\n",
        "                    'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456'],\n",
        "    'Transaction Type': ['Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal'],\n",
        "    'Fraudulent': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
        "                   0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
        "                   1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
        "                   0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
        "}\n",
        "\n",
        "# Creating DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Displaying the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb158cb",
      "metadata": {
        "id": "4eb158cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5091b7ce-4131-4698-ae47-82e932015c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[4 3]\n",
            " [1 0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.57      0.67         7\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         8\n",
            "   macro avg       0.40      0.29      0.33         8\n",
            "weighted avg       0.70      0.50      0.58         8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE]\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, fbeta_score\n",
        "\n",
        "le_merchant = LabelEncoder()\n",
        "le_transaction_type = LabelEncoder()\n",
        "\n",
        "df['Merchant ID Encoded'] = le_merchant.fit_transform(df['Merchant ID'])\n",
        "df['Transaction Type'] = le_transaction_type.fit_transform(df['Transaction Type'])\n",
        "\n",
        "\n",
        "X = df[['Transaction Amount', 'Merchant ID Encoded', 'Transaction Type']]\n",
        "y = df['Fraudulent']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, y_pred)\n",
        "precision_rf = precision_score(y_test, y_pred)\n",
        "recall_rf = recall_score(y_test, y_pred)\n",
        "f2_score_rf = fbeta_score(y_test, y_pred, beta=2)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = {\n",
        "    'Transaction ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
        "                       11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "                       21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
        "                       31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
        "    'Transaction Amount': [1000, 500, 2000, 1500, 800, 3000, 1200, 700, 1800, 1300,\n",
        "                           900, 400, 2200, 1600, 850, 2800, 1100, 600, 1900, 1400,\n",
        "                           950, 300, 2100, 1700, 820, 3200, 1250, 720, 1850, 1350,\n",
        "                           880, 420, 2400, 1750, 830, 3100, 1150, 620, 1950, 1450],\n",
        "    'Merchant ID': ['M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456',\n",
        "                    'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456'],\n",
        "    'Transaction Type': ['Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal'],\n",
        "    'Fraudulent': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
        "                   0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
        "                   1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
        "                   0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df = pd.get_dummies(df, columns=['Merchant ID', 'Transaction Type'], drop_first=True)\n",
        "\n",
        "X = df.drop(['Fraudulent', 'Transaction ID'], axis=1)\n",
        "y = df['Fraudulent']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F2 Score: {f2:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "#Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Non-Fraudulent\", \"Fraudulent\"],\n",
        "            yticklabels=[\"Non-Fraudulent\", \"Fraudulent\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "bdW559qeyLST",
        "outputId": "bfa8fc8b-9515-45b5-8843-2829f712f66b"
      },
      "id": "bdW559qeyLST",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n",
            "Precision: 0.00\n",
            "Recall: 0.00\n",
            "F2 Score: 0.00\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.43      0.43      0.43         8\n",
            "weighted avg       0.75      0.75      0.75         8\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}